{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8a22b4",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "## FINM 36700 - 2023\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "**Professor**\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed795b4",
   "metadata": {},
   "source": [
    "**Students**\n",
    "\n",
    "Kaleem Bukhari kbukhari@uchicago.edu\n",
    "\n",
    "Aditya Murarka adityam@uchicago.edu\n",
    "\n",
    "Raafay Uqaily raafay@uchicago.edu\n",
    "\n",
    "Shrey Jain shreyjain@uchicago.edu\n",
    "\n",
    "Tikhonov Sergei tikhonov@uchicago.edu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732a530",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6302366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from arch import arch_model\n",
    "from arch.univariate import GARCH\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcbdb66",
   "metadata": {},
   "source": [
    "## Helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cded136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_summary(return_data):\n",
    "\n",
    "    summary_stats = return_data.mean().to_frame('Mean').apply(lambda x: x*12)\n",
    "    summary_stats['Volatility'] = return_data.std().apply(lambda x: x*np.sqrt(12))\n",
    "    summary_stats['Sharpe Ratio'] = summary_stats['Mean']/summary_stats['Volatility']\n",
    "    \n",
    "    summary_stats['Skewness'] = return_data.skew()\n",
    "    summary_stats['Excess Kurtosis'] = return_data.kurtosis()\n",
    "    summary_stats['VaR (0.05)'] = return_data.quantile(.05, axis = 0)\n",
    "    summary_stats['CVaR (0.05)'] = return_data[return_data <= return_data.quantile(.05, axis = 0)].mean()\n",
    "    summary_stats['Min'] = return_data.min()\n",
    "    summary_stats['Max'] = return_data.max()\n",
    "    \n",
    "    wealth_index = 1000*(1+return_data).cumprod()\n",
    "    previous_peaks = wealth_index.cummax()\n",
    "    drawdowns = (wealth_index - previous_peaks)/previous_peaks\n",
    "\n",
    "    summary_stats['Max Drawdown'] = drawdowns.min()\n",
    "    summary_stats['Peak'] = [previous_peaks[col][:drawdowns[col].idxmin()].idxmax() for col in previous_peaks.columns]\n",
    "    summary_stats['Bottom'] = drawdowns.idxmin()\n",
    "    \n",
    "    recovery_date = []\n",
    "    for col in wealth_index.columns:\n",
    "        prev_max = previous_peaks[col][:drawdowns[col].idxmin()].max()\n",
    "        recovery_wealth = pd.DataFrame([wealth_index[col][drawdowns[col].idxmin():]]).T\n",
    "        recovery_date.append(recovery_wealth[recovery_wealth[col] >= prev_max].index.min())\n",
    "    summary_stats['Recovery'] = recovery_date\n",
    "    \n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9381a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_based_performance(factor,fund_ret,rf,constant = True):\n",
    "\n",
    "    if constant:\n",
    "        X = sm.tools.add_constant(factor)\n",
    "    else:\n",
    "        X = factor\n",
    "    y=fund_ret\n",
    "    model = sm.OLS(y,X,missing='drop').fit()\n",
    "    \n",
    "    if constant:\n",
    "        beta = model.params[1:]\n",
    "        alpha = round(float(model.params['const']),6) * 12\n",
    "\n",
    "        \n",
    "    else:\n",
    "        beta = model.params\n",
    "    treynor_ratio = ((fund_ret - rf).mean() * 12)/beta[0]\n",
    "    tracking_error = (model.resid.std() * np.sqrt(12))\n",
    "    if constant:        \n",
    "        information_ratio = model.params[0] * 12/tracking_error\n",
    "    r_squared = model.rsquared\n",
    "    if constant:\n",
    "        return (beta,treynor_ratio,information_ratio,alpha,r_squared,tracking_error,model.resid)\n",
    "    else:\n",
    "        return (beta,treynor_ratio,r_squared,tracking_error,model.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce547099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTangencyPortfolio(df):\n",
    "\n",
    "\n",
    "    mean = df.mean() * 12\n",
    "    sigma = df.std() * np.sqrt(12)\n",
    "    cov = df.cov() * 12\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    \n",
    "    w_t = pd.Series(cov_inv @ mean,index = mean.index, name = \"TangencyPortfolio\")\n",
    "    w_t = w_t / sum(w_t)\n",
    "    \n",
    "    tangencyMean = w_t @ mean\n",
    "    tangencyVol = np.sqrt(w_t.T @ cov @ w_t)\n",
    "    tangencySharpe = tangencyMean / tangencyVol\n",
    "    \n",
    "    return w_t,tangencyMean,tangencyVol,tangencySharpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666391de",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9558b0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-31</th>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>-0.0170</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-29</th>\n",
       "      <td>-0.0122</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.0788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-31</th>\n",
       "      <td>-0.1290</td>\n",
       "      <td>-0.0693</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>-0.0119</td>\n",
       "      <td>-0.0955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-04-30</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0210</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>-0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-05-31</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MKT     SMB     HML     RMW     CMA     UMD\n",
       "Date                                                      \n",
       "1980-01-31  0.0551  0.0183  0.0175 -0.0170  0.0164  0.0755\n",
       "1980-02-29 -0.0122 -0.0157  0.0061  0.0004  0.0268  0.0788\n",
       "1980-03-31 -0.1290 -0.0693 -0.0101  0.0146 -0.0119 -0.0955\n",
       "1980-04-30  0.0397  0.0105  0.0106 -0.0210  0.0029 -0.0043\n",
       "1980-05-31  0.0526  0.0211  0.0038  0.0034 -0.0031 -0.0112"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = pd.read_excel('factor_pricing_data.xlsx',sheet_name='descriptions',index_col='Unnamed: 0')\n",
    "factors = pd.read_excel('factor_pricing_data.xlsx',sheet_name='factors (excess returns)',index_col='Date')\n",
    "factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1dcf0e",
   "metadata": {},
   "source": [
    "## 2.1 \n",
    "### Analyze the factors, similar to how you analyzed the three Fama-French factors in Homework 4. You now have three additional factors, so letâ€™s compare there univariate statistics.  \n",
    "- ### mean\n",
    "- ### volatility\n",
    "- ### Sharpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02fe9598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>0.084562</td>\n",
       "      <td>0.157284</td>\n",
       "      <td>0.537641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.100525</td>\n",
       "      <td>0.111476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>0.025324</td>\n",
       "      <td>0.110162</td>\n",
       "      <td>0.229880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.083404</td>\n",
       "      <td>0.557824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.073379</td>\n",
       "      <td>0.442794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.155507</td>\n",
       "      <td>0.391780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean  Volatility  Sharpe Ratio\n",
       "MKT  0.084562    0.157284      0.537641\n",
       "SMB  0.011206    0.100525      0.111476\n",
       "HML  0.025324    0.110162      0.229880\n",
       "RMW  0.046525    0.083404      0.557824\n",
       "CMA  0.032492    0.073379      0.442794\n",
       "UMD  0.060925    0.155507      0.391780"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_summary(factors)[['Mean', 'Volatility', 'Sharpe Ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a51ff2",
   "metadata": {},
   "source": [
    "## 2.2\n",
    "### Based on the factor statistics above, answer the following. <br><br> (a) Does each factor have a positive risk premium (positive expected excess return)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0bc0e1",
   "metadata": {},
   "source": [
    "**Answer**: Yes, all the factors have positive risk premium in the whole sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6696fe7",
   "metadata": {},
   "source": [
    "### (b) How have the factors performed since the time of the case, (2015-present)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b23d0c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.162705</td>\n",
       "      <td>0.686549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>-0.008377</td>\n",
       "      <td>0.098268</td>\n",
       "      <td>-0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>-0.025817</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>-0.190080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.048594</td>\n",
       "      <td>0.073131</td>\n",
       "      <td>0.664483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.086965</td>\n",
       "      <td>0.020631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.144006</td>\n",
       "      <td>0.045144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean  Volatility  Sharpe Ratio\n",
       "MKT  0.111705    0.162705      0.686549\n",
       "SMB -0.008377    0.098268     -0.085244\n",
       "HML -0.025817    0.135825     -0.190080\n",
       "RMW  0.048594    0.073131      0.664483\n",
       "CMA  0.001794    0.086965      0.020631\n",
       "UMD  0.006501    0.144006      0.045144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_summary(factors.loc['2015':])[['Mean', 'Volatility', 'Sharpe Ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c5a7b",
   "metadata": {},
   "source": [
    "**Answer**: Since the time of the case, MKT is still the factor with the highest risk premium. The second and third factors are UMD and RMW, respectively. While CMA is relatively negligible, SMB and HML have shown negative excess return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c9745",
   "metadata": {},
   "source": [
    "## 2.3\n",
    "### Report the correlation matrix across the six factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c62d781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = factors.corr()\n",
    "sns.heatmap(corr, annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d72d48",
   "metadata": {},
   "source": [
    "### (a) Does the construction method succeed in keeping correlations small?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbe4f8",
   "metadata": {},
   "source": [
    "**Answer**: In general, most correlations are relatively small despite a few factors (for example, HML and CMA, SMB and RMW, MKT and CMA). So the construction method indeed succeeded in keeping correlations small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc55a8f",
   "metadata": {},
   "source": [
    "### (b) Fama and French say that HML is somewhat redundant in their 5-factor model. Does this seem to be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d155555",
   "metadata": {},
   "source": [
    "**Answer**: There is a high correlation (0.68) between HML and CMA. That is why we can conclude that in 5-factor model, HML can be seen as a redundant factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb350366",
   "metadata": {},
   "source": [
    "## 2.4\n",
    "### Report the tangency weights for a portfolio of these 6 factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f2dd76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CMA</th>\n",
       "      <th>RMW</th>\n",
       "      <th>MKT</th>\n",
       "      <th>UMD</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tangency Weights</th>\n",
       "      <td>0.369283</td>\n",
       "      <td>0.307353</td>\n",
       "      <td>0.203875</td>\n",
       "      <td>0.093818</td>\n",
       "      <td>0.087446</td>\n",
       "      <td>-0.061776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CMA       RMW       MKT       UMD       SMB       HML\n",
       "Tangency Weights  0.369283  0.307353  0.203875  0.093818  0.087446 -0.061776"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tangencyWt,tangencyMean,tangencyVol, tangencySharpe = computeTangencyPortfolio(factors)\n",
    "tangencyWt.to_frame(\"Tangency Weights\").sort_values('Tangency Weights',ascending = False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61ace0",
   "metadata": {},
   "source": [
    "### (a) Which factors seem most important? And Least?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7244588",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "\n",
    "According to tangency portfolio:\n",
    "\n",
    "The most important factor is CMA, while the least important factor is HML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a6b06",
   "metadata": {},
   "source": [
    "### (b) Are the factors with low mean returns still useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46f4157f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>TangencyPortfolio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>0.084562</td>\n",
       "      <td>0.203875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.093818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.369283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>0.025324</td>\n",
       "      <td>-0.061776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.087446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean  TangencyPortfolio\n",
       "MKT  0.084562           0.203875\n",
       "UMD  0.060925           0.093818\n",
       "RMW  0.046525           0.307353\n",
       "CMA  0.032492           0.369283\n",
       "HML  0.025324          -0.061776\n",
       "SMB  0.011206           0.087446"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([performance_summary(factors)['Mean'], tangencyWt], axis = 1).sort_values('Mean', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c29ac0",
   "metadata": {},
   "source": [
    "**Answer**: As the analysis of tangency weights shows, factors with relatively low mean returns (CMA, RMW) have the largest weights. On the other hand, HML and SMB with the lowest mean returns have the smallest weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cfeda5",
   "metadata": {},
   "source": [
    "### (c) Re-do the tangency portfolio, but this time only include MKT, SMB, HML, and UMD. Which factors get high/low tangency weights now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d0efb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>HML</th>\n",
       "      <th>UMD</th>\n",
       "      <th>SMB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tangency Weights</th>\n",
       "      <td>0.35644</td>\n",
       "      <td>0.348903</td>\n",
       "      <td>0.300861</td>\n",
       "      <td>-0.006204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MKT       HML       UMD       SMB\n",
       "Tangency Weights  0.35644  0.348903  0.300861 -0.006204"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tangencyWt,tangencyMean,tangencyVol, tangencySharpe = computeTangencyPortfolio(factors[['MKT', 'SMB', 'HML', 'UMD']])\n",
    "tangencyWt.to_frame(\"Tangency Weights\").sort_values('Tangency Weights',ascending = False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26671294",
   "metadata": {},
   "source": [
    "**Answer**: for now, HML has the second largest weight even though its returns are one of the lowest among considered factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89eb58",
   "metadata": {},
   "source": [
    "### What do you conclude about the importance or unimportance of these styles?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65b2c3",
   "metadata": {},
   "source": [
    "1. According to correlation-based analysis, we can see that HML looks redundant because of high correlation with CMA.\n",
    "\n",
    "2. According to tangency-based analysis, we can confirm that HML is redundant because it has the lowest weight among the factors\n",
    "\n",
    "3. All other factors fit good (low correlations with each other, more or less high mean returns). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc0cb8",
   "metadata": {},
   "source": [
    "# 3 Testing Modern LPMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189f134",
   "metadata": {},
   "source": [
    "## 1. Test the AQR 4-Factor Model using the time-series test. (We are not doing the cross-sectional regression tests.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f8b45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios = pd.read_excel('factor_pricing_data.xlsx', sheet_name='portfolios (excess returns)', index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32a0cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_test(seriesY, seriesX):\n",
    "    \n",
    "\n",
    "    y = seriesY\n",
    "    X = sm.add_constant(seriesX)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    rsq = model.rsquared\n",
    "    beta = pd.DataFrame(index = [seriesY.name])\n",
    "    \n",
    "    for i,x in enumerate(seriesX):\n",
    "         beta[x] = model.params[i + 1]\n",
    "    \n",
    "    betaCols = [i + 'Beta' for i in seriesX]\n",
    "    beta = beta.rename(columns = dict(zip(beta.columns, betaCols)))\n",
    "    mean = seriesY.mean() * 12\n",
    "    sharpe = mean / (seriesY.std() * (12 ** 0.5))  \n",
    "    treynor = mean / beta[beta.columns[0]]\n",
    "    alpha = model.params[0] * 12\n",
    "    information = alpha/(model.resid.std() * np.sqrt(12))\n",
    "    \n",
    "    RegressionStats = pd.DataFrame({'Mean Return':mean,\n",
    "                                    'Sharpe Ratio':sharpe,\n",
    "                                    'R Squared':rsq,\n",
    "                                    'Alpha':alpha, \n",
    "                                    'Information Ratio':information, \n",
    "                                    'Treynor':treynor}, index= [seriesY.name])\n",
    "    \n",
    "    return pd.concat([RegressionStats,beta], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4ad227a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Return</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>R Squared</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Information Ratio</th>\n",
       "      <th>Treynor</th>\n",
       "      <th>MKTBeta</th>\n",
       "      <th>HMLBeta</th>\n",
       "      <th>RMWBeta</th>\n",
       "      <th>UMDBeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agric</th>\n",
       "      <td>0.089693</td>\n",
       "      <td>0.412541</td>\n",
       "      <td>0.341333</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.053788</td>\n",
       "      <td>0.107052</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.178699</td>\n",
       "      <td>-0.006405</td>\n",
       "      <td>0.084119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food</th>\n",
       "      <td>0.099669</td>\n",
       "      <td>0.660014</td>\n",
       "      <td>0.471088</td>\n",
       "      <td>0.011434</td>\n",
       "      <td>0.104111</td>\n",
       "      <td>0.146377</td>\n",
       "      <td>0.680903</td>\n",
       "      <td>0.169841</td>\n",
       "      <td>0.507359</td>\n",
       "      <td>0.045146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soda</th>\n",
       "      <td>0.108840</td>\n",
       "      <td>0.490980</td>\n",
       "      <td>0.307178</td>\n",
       "      <td>0.019555</td>\n",
       "      <td>0.105981</td>\n",
       "      <td>0.138704</td>\n",
       "      <td>0.784688</td>\n",
       "      <td>0.206106</td>\n",
       "      <td>0.494736</td>\n",
       "      <td>-0.087111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beer</th>\n",
       "      <td>0.119426</td>\n",
       "      <td>0.700661</td>\n",
       "      <td>0.426698</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.187339</td>\n",
       "      <td>0.165106</td>\n",
       "      <td>0.723330</td>\n",
       "      <td>0.025183</td>\n",
       "      <td>0.600586</td>\n",
       "      <td>0.090319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <td>0.132925</td>\n",
       "      <td>0.592263</td>\n",
       "      <td>0.272555</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.184497</td>\n",
       "      <td>0.180305</td>\n",
       "      <td>0.737220</td>\n",
       "      <td>0.249344</td>\n",
       "      <td>0.657434</td>\n",
       "      <td>-0.026824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toys</th>\n",
       "      <td>0.062946</td>\n",
       "      <td>0.252209</td>\n",
       "      <td>0.510315</td>\n",
       "      <td>-0.032189</td>\n",
       "      <td>-0.184306</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>1.116824</td>\n",
       "      <td>-0.035336</td>\n",
       "      <td>0.230797</td>\n",
       "      <td>-0.150169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fun</th>\n",
       "      <td>0.118245</td>\n",
       "      <td>0.446060</td>\n",
       "      <td>0.617319</td>\n",
       "      <td>0.031788</td>\n",
       "      <td>0.193848</td>\n",
       "      <td>0.094682</td>\n",
       "      <td>1.248868</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-0.109524</td>\n",
       "      <td>-0.230768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>0.074122</td>\n",
       "      <td>0.357971</td>\n",
       "      <td>0.689702</td>\n",
       "      <td>-0.030329</td>\n",
       "      <td>-0.262943</td>\n",
       "      <td>0.066563</td>\n",
       "      <td>1.113566</td>\n",
       "      <td>0.265474</td>\n",
       "      <td>0.177919</td>\n",
       "      <td>-0.077390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hshld</th>\n",
       "      <td>0.081545</td>\n",
       "      <td>0.529226</td>\n",
       "      <td>0.560258</td>\n",
       "      <td>-0.005510</td>\n",
       "      <td>-0.053928</td>\n",
       "      <td>0.108322</td>\n",
       "      <td>0.752802</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.485108</td>\n",
       "      <td>0.013206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clths</th>\n",
       "      <td>0.098083</td>\n",
       "      <td>0.437351</td>\n",
       "      <td>0.631763</td>\n",
       "      <td>-0.011724</td>\n",
       "      <td>-0.086150</td>\n",
       "      <td>0.087683</td>\n",
       "      <td>1.118614</td>\n",
       "      <td>0.049475</td>\n",
       "      <td>0.564987</td>\n",
       "      <td>-0.202276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hlth</th>\n",
       "      <td>0.080281</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>0.444824</td>\n",
       "      <td>-0.037288</td>\n",
       "      <td>-0.214220</td>\n",
       "      <td>0.076983</td>\n",
       "      <td>1.042843</td>\n",
       "      <td>0.117548</td>\n",
       "      <td>0.454208</td>\n",
       "      <td>0.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedEq</th>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.564162</td>\n",
       "      <td>0.600067</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>0.205774</td>\n",
       "      <td>0.115765</td>\n",
       "      <td>0.876772</td>\n",
       "      <td>-0.147144</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>0.049555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drugs</th>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.627885</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>0.269910</td>\n",
       "      <td>0.140059</td>\n",
       "      <td>0.730212</td>\n",
       "      <td>-0.159870</td>\n",
       "      <td>0.210362</td>\n",
       "      <td>0.062399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chems</th>\n",
       "      <td>0.087079</td>\n",
       "      <td>0.430772</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>-0.023092</td>\n",
       "      <td>-0.227710</td>\n",
       "      <td>0.077077</td>\n",
       "      <td>1.129765</td>\n",
       "      <td>0.289457</td>\n",
       "      <td>0.297728</td>\n",
       "      <td>-0.107454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rubbr</th>\n",
       "      <td>0.099008</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>0.646630</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.092901</td>\n",
       "      <td>1.065742</td>\n",
       "      <td>0.098180</td>\n",
       "      <td>0.139608</td>\n",
       "      <td>-0.074495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Txtls</th>\n",
       "      <td>0.081380</td>\n",
       "      <td>0.294980</td>\n",
       "      <td>0.557809</td>\n",
       "      <td>-0.028386</td>\n",
       "      <td>-0.154731</td>\n",
       "      <td>0.066399</td>\n",
       "      <td>1.225619</td>\n",
       "      <td>0.532835</td>\n",
       "      <td>0.289758</td>\n",
       "      <td>-0.342219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BldMt</th>\n",
       "      <td>0.099499</td>\n",
       "      <td>0.444945</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>-0.028049</td>\n",
       "      <td>-0.255470</td>\n",
       "      <td>0.078416</td>\n",
       "      <td>1.268867</td>\n",
       "      <td>0.313205</td>\n",
       "      <td>0.384226</td>\n",
       "      <td>-0.091214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnstr</th>\n",
       "      <td>0.096551</td>\n",
       "      <td>0.379947</td>\n",
       "      <td>0.635205</td>\n",
       "      <td>-0.034357</td>\n",
       "      <td>-0.223848</td>\n",
       "      <td>0.072226</td>\n",
       "      <td>1.336787</td>\n",
       "      <td>0.266041</td>\n",
       "      <td>0.218419</td>\n",
       "      <td>0.015867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steel</th>\n",
       "      <td>0.070428</td>\n",
       "      <td>0.239674</td>\n",
       "      <td>0.630969</td>\n",
       "      <td>-0.025503</td>\n",
       "      <td>-0.142866</td>\n",
       "      <td>0.050262</td>\n",
       "      <td>1.401215</td>\n",
       "      <td>0.338470</td>\n",
       "      <td>-0.451780</td>\n",
       "      <td>-0.165963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FabPr</th>\n",
       "      <td>0.061145</td>\n",
       "      <td>0.223263</td>\n",
       "      <td>0.420043</td>\n",
       "      <td>-0.020730</td>\n",
       "      <td>-0.099392</td>\n",
       "      <td>0.056237</td>\n",
       "      <td>1.087275</td>\n",
       "      <td>0.176516</td>\n",
       "      <td>-0.073052</td>\n",
       "      <td>-0.182834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mach</th>\n",
       "      <td>0.090941</td>\n",
       "      <td>0.395948</td>\n",
       "      <td>0.753203</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>-0.011482</td>\n",
       "      <td>0.073939</td>\n",
       "      <td>1.229938</td>\n",
       "      <td>0.093030</td>\n",
       "      <td>-0.128851</td>\n",
       "      <td>-0.133222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElcEq</th>\n",
       "      <td>0.111403</td>\n",
       "      <td>0.487896</td>\n",
       "      <td>0.745137</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.034557</td>\n",
       "      <td>0.088841</td>\n",
       "      <td>1.253950</td>\n",
       "      <td>-0.007111</td>\n",
       "      <td>0.098948</td>\n",
       "      <td>-0.049913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autos</th>\n",
       "      <td>0.108135</td>\n",
       "      <td>0.366391</td>\n",
       "      <td>0.555082</td>\n",
       "      <td>0.014419</td>\n",
       "      <td>0.073244</td>\n",
       "      <td>0.083196</td>\n",
       "      <td>1.299762</td>\n",
       "      <td>0.183877</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>-0.378461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aero</th>\n",
       "      <td>0.104150</td>\n",
       "      <td>0.456119</td>\n",
       "      <td>0.601289</td>\n",
       "      <td>-0.008997</td>\n",
       "      <td>-0.062402</td>\n",
       "      <td>0.091421</td>\n",
       "      <td>1.139232</td>\n",
       "      <td>0.290246</td>\n",
       "      <td>0.373064</td>\n",
       "      <td>-0.129595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ships</th>\n",
       "      <td>0.088711</td>\n",
       "      <td>0.340209</td>\n",
       "      <td>0.505822</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.228170</td>\n",
       "      <td>0.073053</td>\n",
       "      <td>1.214326</td>\n",
       "      <td>0.417844</td>\n",
       "      <td>0.438418</td>\n",
       "      <td>-0.051373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guns</th>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.501480</td>\n",
       "      <td>0.335597</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.132855</td>\n",
       "      <td>0.823450</td>\n",
       "      <td>0.264897</td>\n",
       "      <td>0.627627</td>\n",
       "      <td>0.039940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gold</th>\n",
       "      <td>0.053124</td>\n",
       "      <td>0.136796</td>\n",
       "      <td>0.050383</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.094710</td>\n",
       "      <td>0.560907</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>-0.036594</td>\n",
       "      <td>0.073549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mines</th>\n",
       "      <td>0.084195</td>\n",
       "      <td>0.303234</td>\n",
       "      <td>0.465124</td>\n",
       "      <td>-0.019166</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>0.070344</td>\n",
       "      <td>1.196900</td>\n",
       "      <td>0.326034</td>\n",
       "      <td>0.054946</td>\n",
       "      <td>-0.142204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coal</th>\n",
       "      <td>0.076038</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.220958</td>\n",
       "      <td>-0.034908</td>\n",
       "      <td>-0.099598</td>\n",
       "      <td>0.063303</td>\n",
       "      <td>1.201187</td>\n",
       "      <td>0.537158</td>\n",
       "      <td>-0.278670</td>\n",
       "      <td>0.143339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oil</th>\n",
       "      <td>0.088867</td>\n",
       "      <td>0.391937</td>\n",
       "      <td>0.465899</td>\n",
       "      <td>-0.022503</td>\n",
       "      <td>-0.135801</td>\n",
       "      <td>0.088657</td>\n",
       "      <td>1.002366</td>\n",
       "      <td>0.627247</td>\n",
       "      <td>0.150687</td>\n",
       "      <td>0.060929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Util</th>\n",
       "      <td>0.074969</td>\n",
       "      <td>0.543107</td>\n",
       "      <td>0.356958</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>0.137166</td>\n",
       "      <td>0.546555</td>\n",
       "      <td>0.317718</td>\n",
       "      <td>0.212875</td>\n",
       "      <td>0.099185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telcm</th>\n",
       "      <td>0.071073</td>\n",
       "      <td>0.409163</td>\n",
       "      <td>0.589162</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.053416</td>\n",
       "      <td>0.085418</td>\n",
       "      <td>0.832063</td>\n",
       "      <td>0.104903</td>\n",
       "      <td>-0.062412</td>\n",
       "      <td>-0.081872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PerSv</th>\n",
       "      <td>0.062545</td>\n",
       "      <td>0.295240</td>\n",
       "      <td>0.582222</td>\n",
       "      <td>-0.052220</td>\n",
       "      <td>-0.381370</td>\n",
       "      <td>0.057809</td>\n",
       "      <td>1.081919</td>\n",
       "      <td>0.153490</td>\n",
       "      <td>0.300333</td>\n",
       "      <td>0.088880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BusSv</th>\n",
       "      <td>0.089298</td>\n",
       "      <td>0.473564</td>\n",
       "      <td>0.852923</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>-0.005064</td>\n",
       "      <td>0.082107</td>\n",
       "      <td>1.087577</td>\n",
       "      <td>-0.127397</td>\n",
       "      <td>0.019408</td>\n",
       "      <td>0.000320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardw</th>\n",
       "      <td>0.088240</td>\n",
       "      <td>0.340798</td>\n",
       "      <td>0.669483</td>\n",
       "      <td>0.042445</td>\n",
       "      <td>0.285142</td>\n",
       "      <td>0.080198</td>\n",
       "      <td>1.100272</td>\n",
       "      <td>-0.465209</td>\n",
       "      <td>-0.492153</td>\n",
       "      <td>-0.206289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Softw</th>\n",
       "      <td>0.136990</td>\n",
       "      <td>0.498626</td>\n",
       "      <td>0.738742</td>\n",
       "      <td>0.066834</td>\n",
       "      <td>0.475933</td>\n",
       "      <td>0.112078</td>\n",
       "      <td>1.222273</td>\n",
       "      <td>-0.855465</td>\n",
       "      <td>-0.141328</td>\n",
       "      <td>-0.081450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chips</th>\n",
       "      <td>0.121310</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.753552</td>\n",
       "      <td>0.061967</td>\n",
       "      <td>0.470018</td>\n",
       "      <td>0.099246</td>\n",
       "      <td>1.222322</td>\n",
       "      <td>-0.538878</td>\n",
       "      <td>-0.486099</td>\n",
       "      <td>-0.127313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabEq</th>\n",
       "      <td>0.099708</td>\n",
       "      <td>0.431349</td>\n",
       "      <td>0.737682</td>\n",
       "      <td>0.029572</td>\n",
       "      <td>0.249783</td>\n",
       "      <td>0.088845</td>\n",
       "      <td>1.122269</td>\n",
       "      <td>-0.362816</td>\n",
       "      <td>-0.341097</td>\n",
       "      <td>0.004792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paper</th>\n",
       "      <td>0.068299</td>\n",
       "      <td>0.360480</td>\n",
       "      <td>0.676739</td>\n",
       "      <td>-0.037549</td>\n",
       "      <td>-0.348573</td>\n",
       "      <td>0.067432</td>\n",
       "      <td>1.012861</td>\n",
       "      <td>0.243555</td>\n",
       "      <td>0.412502</td>\n",
       "      <td>-0.084701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boxes</th>\n",
       "      <td>0.092398</td>\n",
       "      <td>0.462944</td>\n",
       "      <td>0.586154</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.094565</td>\n",
       "      <td>0.977081</td>\n",
       "      <td>0.116515</td>\n",
       "      <td>0.255496</td>\n",
       "      <td>-0.117838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trans</th>\n",
       "      <td>0.090785</td>\n",
       "      <td>0.452969</td>\n",
       "      <td>0.707433</td>\n",
       "      <td>-0.017072</td>\n",
       "      <td>-0.157477</td>\n",
       "      <td>0.083035</td>\n",
       "      <td>1.093328</td>\n",
       "      <td>0.189071</td>\n",
       "      <td>0.352329</td>\n",
       "      <td>-0.094835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whlsl</th>\n",
       "      <td>0.085521</td>\n",
       "      <td>0.473165</td>\n",
       "      <td>0.756767</td>\n",
       "      <td>-0.013517</td>\n",
       "      <td>-0.151638</td>\n",
       "      <td>0.082898</td>\n",
       "      <td>1.031640</td>\n",
       "      <td>0.099153</td>\n",
       "      <td>0.185132</td>\n",
       "      <td>0.011102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rtail</th>\n",
       "      <td>0.111818</td>\n",
       "      <td>0.596456</td>\n",
       "      <td>0.683464</td>\n",
       "      <td>0.019527</td>\n",
       "      <td>0.185137</td>\n",
       "      <td>0.113938</td>\n",
       "      <td>0.981389</td>\n",
       "      <td>-0.140767</td>\n",
       "      <td>0.347550</td>\n",
       "      <td>-0.054203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meals</th>\n",
       "      <td>0.103863</td>\n",
       "      <td>0.569968</td>\n",
       "      <td>0.643047</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.022844</td>\n",
       "      <td>0.109533</td>\n",
       "      <td>0.948235</td>\n",
       "      <td>0.080657</td>\n",
       "      <td>0.500334</td>\n",
       "      <td>-0.067775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banks</th>\n",
       "      <td>0.088988</td>\n",
       "      <td>0.413863</td>\n",
       "      <td>0.772044</td>\n",
       "      <td>-0.022979</td>\n",
       "      <td>-0.223835</td>\n",
       "      <td>0.076764</td>\n",
       "      <td>1.159250</td>\n",
       "      <td>0.721895</td>\n",
       "      <td>0.087560</td>\n",
       "      <td>-0.138145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insur</th>\n",
       "      <td>0.095899</td>\n",
       "      <td>0.526738</td>\n",
       "      <td>0.685298</td>\n",
       "      <td>-0.008563</td>\n",
       "      <td>-0.083839</td>\n",
       "      <td>0.097882</td>\n",
       "      <td>0.979743</td>\n",
       "      <td>0.479804</td>\n",
       "      <td>0.222779</td>\n",
       "      <td>-0.014815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RlEst</th>\n",
       "      <td>0.048103</td>\n",
       "      <td>0.192725</td>\n",
       "      <td>0.603615</td>\n",
       "      <td>-0.056717</td>\n",
       "      <td>-0.360927</td>\n",
       "      <td>0.040084</td>\n",
       "      <td>1.200074</td>\n",
       "      <td>0.490751</td>\n",
       "      <td>0.062269</td>\n",
       "      <td>-0.196719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fin</th>\n",
       "      <td>0.110258</td>\n",
       "      <td>0.493620</td>\n",
       "      <td>0.812962</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>0.188842</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>1.238895</td>\n",
       "      <td>0.327216</td>\n",
       "      <td>-0.401302</td>\n",
       "      <td>-0.038805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.050820</td>\n",
       "      <td>0.239526</td>\n",
       "      <td>0.595904</td>\n",
       "      <td>-0.045176</td>\n",
       "      <td>-0.334950</td>\n",
       "      <td>0.047921</td>\n",
       "      <td>1.060498</td>\n",
       "      <td>0.087573</td>\n",
       "      <td>0.117101</td>\n",
       "      <td>-0.022131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean Return  Sharpe Ratio  R Squared     Alpha  Information Ratio  \\\n",
       "Agric     0.089693      0.412541   0.341333  0.009491           0.053788   \n",
       "Food      0.099669      0.660014   0.471088  0.011434           0.104111   \n",
       "Soda      0.108840      0.490980   0.307178  0.019555           0.105981   \n",
       "Beer      0.119426      0.700661   0.426698  0.024178           0.187339   \n",
       "Smoke     0.132925      0.592263   0.272555  0.035317           0.184497   \n",
       "Toys      0.062946      0.252209   0.510315 -0.032189          -0.184306   \n",
       "Fun       0.118245      0.446060   0.617319  0.031788           0.193848   \n",
       "Books     0.074122      0.357971   0.689702 -0.030329          -0.262943   \n",
       "Hshld     0.081545      0.529226   0.560258 -0.005510          -0.053928   \n",
       "Clths     0.098083      0.437351   0.631763 -0.011724          -0.086150   \n",
       "Hlth      0.080281      0.343655   0.444824 -0.037288          -0.214220   \n",
       "MedEq     0.101500      0.564162   0.600067  0.023412           0.205774   \n",
       "Drugs     0.102273      0.627885   0.503302  0.030985           0.269910   \n",
       "Chems     0.087079      0.430772   0.748344 -0.023092          -0.227710   \n",
       "Rubbr     0.099008      0.479459   0.646630  0.004444           0.036200   \n",
       "Txtls     0.081380      0.294980   0.557809 -0.028386          -0.154731   \n",
       "BldMt     0.099499      0.444945   0.758929 -0.028049          -0.255470   \n",
       "Cnstr     0.096551      0.379947   0.635205 -0.034357          -0.223848   \n",
       "Steel     0.070428      0.239674   0.630969 -0.025503          -0.142866   \n",
       "FabPr     0.061145      0.223263   0.420043 -0.020730          -0.099392   \n",
       "Mach      0.090941      0.395948   0.753203 -0.001310          -0.011482   \n",
       "ElcEq     0.111403      0.487896   0.745137  0.003983           0.034557   \n",
       "Autos     0.108135      0.366391   0.555082  0.014419           0.073244   \n",
       "Aero      0.104150      0.456119   0.601289 -0.008997          -0.062402   \n",
       "Ships     0.088711      0.340209   0.505822 -0.041824          -0.228170   \n",
       "Guns      0.109400      0.501480   0.335597  0.001425           0.008015   \n",
       "Gold      0.053124      0.136796   0.050383  0.002429           0.006418   \n",
       "Mines     0.084195      0.303234   0.465124 -0.019166          -0.094386   \n",
       "Coal      0.076038      0.191489   0.220958 -0.034908          -0.099598   \n",
       "Oil       0.088867      0.391937   0.465899 -0.022503          -0.135801   \n",
       "Util      0.074969      0.543107   0.356958  0.004759           0.042989   \n",
       "Telcm     0.071073      0.409163   0.589162  0.005947           0.053416   \n",
       "PerSv     0.062545      0.295240   0.582222 -0.052220          -0.381370   \n",
       "BusSv     0.089298      0.473564   0.852923 -0.000366          -0.005064   \n",
       "Hardw     0.088240      0.340798   0.669483  0.042445           0.285142   \n",
       "Softw     0.136990      0.498626   0.738742  0.066834           0.475933   \n",
       "Chips     0.121310      0.456790   0.753552  0.061967           0.470018   \n",
       "LabEq     0.099708      0.431349   0.737682  0.029572           0.249783   \n",
       "Paper     0.068299      0.360480   0.676739 -0.037549          -0.348573   \n",
       "Boxes     0.092398      0.462944   0.586154  0.002115           0.016476   \n",
       "Trans     0.090785      0.452969   0.707433 -0.017072          -0.157477   \n",
       "Whlsl     0.085521      0.473165   0.756767 -0.013517          -0.151638   \n",
       "Rtail     0.111818      0.596456   0.683464  0.019527           0.185137   \n",
       "Meals     0.103863      0.569968   0.643047  0.002487           0.022844   \n",
       "Banks     0.088988      0.413863   0.772044 -0.022979          -0.223835   \n",
       "Insur     0.095899      0.526738   0.685298 -0.008563          -0.083839   \n",
       "RlEst     0.048103      0.192725   0.603615 -0.056717          -0.360927   \n",
       "Fin       0.110258      0.493620   0.812962  0.018242           0.188842   \n",
       "Other     0.050820      0.239526   0.595904 -0.045176          -0.334950   \n",
       "\n",
       "        Treynor   MKTBeta   HMLBeta   RMWBeta   UMDBeta  \n",
       "Agric  0.107052  0.837838  0.178699 -0.006405  0.084119  \n",
       "Food   0.146377  0.680903  0.169841  0.507359  0.045146  \n",
       "Soda   0.138704  0.784688  0.206106  0.494736 -0.087111  \n",
       "Beer   0.165106  0.723330  0.025183  0.600586  0.090319  \n",
       "Smoke  0.180305  0.737220  0.249344  0.657434 -0.026824  \n",
       "Toys   0.056362  1.116824 -0.035336  0.230797 -0.150169  \n",
       "Fun    0.094682  1.248868  0.000177 -0.109524 -0.230768  \n",
       "Books  0.066563  1.113566  0.265474  0.177919 -0.077390  \n",
       "Hshld  0.108322  0.752802  0.000889  0.485108  0.013206  \n",
       "Clths  0.087683  1.118614  0.049475  0.564987 -0.202276  \n",
       "Hlth   0.076983  1.042843  0.117548  0.454208  0.086577  \n",
       "MedEq  0.115765  0.876772 -0.147144  0.100010  0.049555  \n",
       "Drugs  0.140059  0.730212 -0.159870  0.210362  0.062399  \n",
       "Chems  0.077077  1.129765  0.289457  0.297728 -0.107454  \n",
       "Rubbr  0.092901  1.065742  0.098180  0.139608 -0.074495  \n",
       "Txtls  0.066399  1.225619  0.532835  0.289758 -0.342219  \n",
       "BldMt  0.078416  1.268867  0.313205  0.384226 -0.091214  \n",
       "Cnstr  0.072226  1.336787  0.266041  0.218419  0.015867  \n",
       "Steel  0.050262  1.401215  0.338470 -0.451780 -0.165963  \n",
       "FabPr  0.056237  1.087275  0.176516 -0.073052 -0.182834  \n",
       "Mach   0.073939  1.229938  0.093030 -0.128851 -0.133222  \n",
       "ElcEq  0.088841  1.253950 -0.007111  0.098948 -0.049913  \n",
       "Autos  0.083196  1.299762  0.183877  0.047432 -0.378461  \n",
       "Aero   0.091421  1.139232  0.290246  0.373064 -0.129595  \n",
       "Ships  0.073053  1.214326  0.417844  0.438418 -0.051373  \n",
       "Guns   0.132855  0.823450  0.264897  0.627627  0.039940  \n",
       "Gold   0.094710  0.560907  0.019144 -0.036594  0.073549  \n",
       "Mines  0.070344  1.196900  0.326034  0.054946 -0.142204  \n",
       "Coal   0.063303  1.201187  0.537158 -0.278670  0.143339  \n",
       "Oil    0.088657  1.002366  0.627247  0.150687  0.060929  \n",
       "Util   0.137166  0.546555  0.317718  0.212875  0.099185  \n",
       "Telcm  0.085418  0.832063  0.104903 -0.062412 -0.081872  \n",
       "PerSv  0.057809  1.081919  0.153490  0.300333  0.088880  \n",
       "BusSv  0.082107  1.087577 -0.127397  0.019408  0.000320  \n",
       "Hardw  0.080198  1.100272 -0.465209 -0.492153 -0.206289  \n",
       "Softw  0.112078  1.222273 -0.855465 -0.141328 -0.081450  \n",
       "Chips  0.099246  1.222322 -0.538878 -0.486099 -0.127313  \n",
       "LabEq  0.088845  1.122269 -0.362816 -0.341097  0.004792  \n",
       "Paper  0.067432  1.012861  0.243555  0.412502 -0.084701  \n",
       "Boxes  0.094565  0.977081  0.116515  0.255496 -0.117838  \n",
       "Trans  0.083035  1.093328  0.189071  0.352329 -0.094835  \n",
       "Whlsl  0.082898  1.031640  0.099153  0.185132  0.011102  \n",
       "Rtail  0.113938  0.981389 -0.140767  0.347550 -0.054203  \n",
       "Meals  0.109533  0.948235  0.080657  0.500334 -0.067775  \n",
       "Banks  0.076764  1.159250  0.721895  0.087560 -0.138145  \n",
       "Insur  0.097882  0.979743  0.479804  0.222779 -0.014815  \n",
       "RlEst  0.040084  1.200074  0.490751  0.062269 -0.196719  \n",
       "Fin    0.088997  1.238895  0.327216 -0.401302 -0.038805  \n",
       "Other  0.047921  1.060498  0.087573  0.117101 -0.022131  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqr = factors[['MKT', 'HML', 'RMW', 'UMD']]\n",
    "\n",
    "frames = []\n",
    "\n",
    "for col in portfolios:\n",
    "    \n",
    "    p = time_series_test(portfolios[col], aqr)\n",
    "    frames.append(p) \n",
    "    \n",
    "AQRRegression = pd.concat(frames)\n",
    "AQRRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "361d187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean Return          0.091234\n",
       "Sharpe Ratio         0.422665\n",
       "R Squared            0.577081\n",
       "Alpha               -0.003944\n",
       "Information Ratio   -0.023078\n",
       "Treynor              0.091504\n",
       "MKTBeta              1.042857\n",
       "HMLBeta              0.134882\n",
       "RMWBeta              0.156546\n",
       "UMDBeta             -0.060840\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AQRRegression.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce4f49",
   "metadata": {},
   "source": [
    "### Calculate the mean-absolute-error of the estimated alphas, (one for each security, Ëœri.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f60e41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for AQR factors: 0.022995\n"
     ]
    }
   ],
   "source": [
    "AQR_MAE = round(abs(AQRRegression['Alpha']).mean(), 6)\n",
    "print(f'Mean Absolute Error for AQR factors: {AQR_MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d08f9b0",
   "metadata": {},
   "source": [
    "### If the pricing model worked, should these alpha estimates be large or small? Why? Based on your MAE stat, does this seem to support the pricing model or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d5b6e",
   "metadata": {},
   "source": [
    "**Answer**: Theoretically, alphas must be zero since the factors must be sufficient to explain most of the variation in excess portfolio return. However, since we use statistical approach, due to the noise in observations, alphas should be small. Here we see that mean absolue error for AQR factors is relatively small. That's why we can conclude, based on MAE, that the AQR pricing model is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a126c2d",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "### Test the CAPM, FF 3-Factor Model and the the FF 5-Factor Model. Report the MAE statistic for each of these models and compare it with the AQR Model MAE. Which model fits best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ca48016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error CAPM: 0.020608\n"
     ]
    }
   ],
   "source": [
    "mkt = factors[['MKT']]\n",
    "\n",
    "frames = []\n",
    "\n",
    "for col in portfolios:\n",
    "    \n",
    "    p = time_series_test(portfolios[col], mkt)\n",
    "    frames.append(p) \n",
    "    \n",
    "mktRegression = pd.concat(frames)\n",
    "mkt_MAE = round(abs(mktRegression['Alpha']).mean(), 6)\n",
    "print(f'Mean Absolute Error CAPM: {mkt_MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3977563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean Return          0.091234\n",
       "Sharpe Ratio         0.422665\n",
       "R Squared            0.528087\n",
       "Alpha                0.005495\n",
       "Information Ratio    0.045943\n",
       "Treynor              0.096156\n",
       "MKTBeta              1.013924\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mktRegression.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dbdd405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error CAPM: 0.0242\n"
     ]
    }
   ],
   "source": [
    "ff3 = factors[['MKT', 'SMB', 'HML']]\n",
    "\n",
    "frames = []\n",
    "\n",
    "for col in portfolios:\n",
    "    \n",
    "    p = time_series_test(portfolios[col], ff3)\n",
    "    frames.append(p) \n",
    "    \n",
    "ff3Regression = pd.concat(frames)\n",
    "ff3_MAE = round(abs(ff3Regression['Alpha']).mean(), 6)\n",
    "print(f'Mean Absolute Error CAPM: {ff3_MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab9b5a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean Return          0.091234\n",
       "Sharpe Ratio         0.422665\n",
       "R Squared            0.572516\n",
       "Alpha               -0.001156\n",
       "Information Ratio    0.000099\n",
       "Treynor              0.094123\n",
       "MKTBeta              1.016358\n",
       "SMBBeta              0.167483\n",
       "HMLBeta              0.180372\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff3Regression.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6836c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error CAPM: 0.031272\n"
     ]
    }
   ],
   "source": [
    "ff5 = factors[['MKT', 'SMB', 'HML', 'RMW', 'CMA']]\n",
    "\n",
    "frames = []\n",
    "\n",
    "for col in portfolios:\n",
    "    \n",
    "    p = time_series_test(portfolios[col], ff5)\n",
    "    frames.append(p) \n",
    "    \n",
    "ff5Regression = pd.concat(frames)\n",
    "ff5_MAE = round(abs(ff5Regression['Alpha']).mean(), 6)\n",
    "print(f'Mean Absolute Error CAPM: {ff5_MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e32c98ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean Return          0.091234\n",
       "Sharpe Ratio         0.422665\n",
       "R Squared            0.597519\n",
       "Alpha               -0.018618\n",
       "Information Ratio   -0.127044\n",
       "Treynor              0.090187\n",
       "MKTBeta              1.044790\n",
       "SMBBeta              0.251245\n",
       "HMLBeta              0.095741\n",
       "RMWBeta              0.272760\n",
       "CMABeta              0.109949\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff5Regression.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d302df1a",
   "metadata": {},
   "source": [
    "**Answer**: according to MAE error, CAPM fits the best among FF 3-Factor model, FF 5-Factor model, and AQR model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6ae33",
   "metadata": {},
   "source": [
    "## 3.3\n",
    "### Does any particular factor seem especially important or unimportant for pricing? Do you think Fama and French should use the Momentum Factor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55246bd",
   "metadata": {},
   "source": [
    "**Answer**: Market factor is indeed the most important factor in all factor models we tested. Considering other factors, we can see that the weights of different factors change from one factor model to another, that's why we cannot be sure that those factors are unimportant for pricing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de68c3",
   "metadata": {},
   "source": [
    "**Answer**: Fama is the creator of the efficient market hypothesis. The existance of momentum factor would indeed contradict to his theory, that was probably a reason why he didn't include this factor to his factor model. However, according to the calculations above, we can see that momentum is an important factor, because AQR performance is higher than each FF 3 Factor model and FF 5 Factor model (even though the weight of UMD is the lowest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60c5a5",
   "metadata": {},
   "source": [
    "## 3.4\n",
    "### This does not matter for pricing, but report the average (across n estimations) of the time-series regression r-squared statistics. Do this for each of the three models you tested. Do these models lead to high time-series r-squared stats? That is, would these factors be good in a Linear Factor Decomposition of the assets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e050dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>AQR</th>\n",
       "      <th>FF3</th>\n",
       "      <th>FF5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average R Squared</th>\n",
       "      <td>0.528087</td>\n",
       "      <td>0.577081</td>\n",
       "      <td>0.578308</td>\n",
       "      <td>0.597519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MKT       AQR       FF3       FF5\n",
       "Average R Squared  0.528087  0.577081  0.578308  0.597519"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MKT_RSq = mktRegression['R Squared'].mean()\n",
    "AQR_RSq = AQRRegression['R Squared'].mean()\n",
    "FF3_RSq = ff3Regression['R Squared'].mean()\n",
    "FF5_RSq = ff5Regression['R Squared'].mean()\n",
    "\n",
    "Average_R_Squared = pd.Series({'MKT': MKT_RSq, 'AQR':AQR_RSq,'FF3':FF3_RSq,'FF5':FF5_RSq})\n",
    "Average_R_Squared.to_frame(\"Average R Squared\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699928ff",
   "metadata": {},
   "source": [
    "**Answer**: R2 of all factors are in range from 0.52 to 0.59. This is a relatively poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62938b",
   "metadata": {},
   "source": [
    "## 3.5\n",
    "### We tested three models using the time-series tests (focusing on the time-series alphas.) Re-test these models, but this time use the cross-sectional test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed333881",
   "metadata": {},
   "source": [
    "### (a) Report the time-series premia of the factors (just their sample averages,) and compare to the cross-sectionally estimated premia of the factors. Do they differ substantially?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f472731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKTBeta</th>\n",
       "      <th>SMBBeta</th>\n",
       "      <th>HMLBeta</th>\n",
       "      <th>RMWBeta</th>\n",
       "      <th>CMABeta</th>\n",
       "      <th>UMDBeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time Series Premia</th>\n",
       "      <td>0.084562</td>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.025324</td>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.060925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MKTBeta   SMBBeta   HMLBeta   RMWBeta   CMABeta   UMDBeta\n",
       "Time Series Premia  0.084562  0.011206  0.025324  0.046525  0.032492  0.060925"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_premia = (factors.mean()*12).to_frame('Time Series Premia')\n",
    "time_series_premia.index = [x+\"Beta\" for x in time_series_premia.index]\n",
    "time_series_premia.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f6a0241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKTBeta</th>\n",
       "      <th>HMLBeta</th>\n",
       "      <th>RMWBeta</th>\n",
       "      <th>UMDBeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AQR CS Premia</th>\n",
       "      <td>0.087644</td>\n",
       "      <td>-0.039757</td>\n",
       "      <td>0.044399</td>\n",
       "      <td>0.053375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MKTBeta   HMLBeta   RMWBeta   UMDBeta\n",
       "AQR CS Premia  0.087644 -0.039757  0.044399  0.053375"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = AQRRegression['Mean Return']\n",
    "x = AQRRegression[['MKTBeta','HMLBeta','RMWBeta','UMDBeta']]\n",
    "AQRRegressionCS = sm.OLS(y,x,missing='drop').fit()\n",
    "AQR_CS_MAE = AQRRegressionCS.resid.abs().mean()\n",
    "AQR_CS_premia = AQRRegressionCS.params.to_frame(\"AQR CS Premia\")\n",
    "AQR_CS_premia.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a7a5f888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKTBeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAPM CS Premia</th>\n",
       "      <td>0.085667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MKTBeta\n",
       "CAPM CS Premia  0.085667"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = mktRegression['Mean Return']\n",
    "x = mktRegression[['MKTBeta']]\n",
    "AQRRegressionCS = sm.OLS(y, x, missing='drop').fit()\n",
    "CAPM_CS_MAE = AQRRegressionCS.resid.abs().mean()\n",
    "CAPM_CS_premia = AQRRegressionCS.params.to_frame(\"CAPM CS Premia\")\n",
    "CAPM_CS_premia.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a62bffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKTBeta</th>\n",
       "      <th>SMBBeta</th>\n",
       "      <th>HMLBeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FF3 CS Premia</th>\n",
       "      <td>0.10217</td>\n",
       "      <td>-0.06256</td>\n",
       "      <td>-0.015919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MKTBeta  SMBBeta   HMLBeta\n",
       "FF3 CS Premia  0.10217 -0.06256 -0.015919"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ff3Regression['Mean Return']\n",
    "x = ff3Regression[['MKTBeta','SMBBeta','HMLBeta']]\n",
    "FF3RegressionCS = sm.OLS(y, x, missing='drop').fit()\n",
    "FF3_CS_MAE = FF3RegressionCS.resid.abs().mean()\n",
    "FF3_CS_Premia = FF3RegressionCS.params.to_frame(\"FF3 CS Premia\")\n",
    "FF3_CS_Premia.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e9556b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKTBeta</th>\n",
       "      <th>SMBBeta</th>\n",
       "      <th>HMLBeta</th>\n",
       "      <th>RMWBeta</th>\n",
       "      <th>CMABeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FF5 CS Premia</th>\n",
       "      <td>0.095697</td>\n",
       "      <td>-0.057674</td>\n",
       "      <td>-0.033504</td>\n",
       "      <td>0.035899</td>\n",
       "      <td>-0.015156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MKTBeta   SMBBeta   HMLBeta   RMWBeta   CMABeta\n",
       "FF5 CS Premia  0.095697 -0.057674 -0.033504  0.035899 -0.015156"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ff5Regression['Mean Return']\n",
    "x = ff5Regression[['MKTBeta','SMBBeta','HMLBeta','RMWBeta','CMABeta']]\n",
    "FF5RegressionCS = sm.OLS(y, x, missing='drop').fit()\n",
    "FF5_CS_MAE = FF5RegressionCS.resid.abs().mean()\n",
    "FF5_CS_Premia = FF5RegressionCS.params.to_frame(\"FF5 CS Premia\")\n",
    "FF5_CS_Premia.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "971c2620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Series Premia</th>\n",
       "      <th>CAPM CS Premia</th>\n",
       "      <th>FF3 CS Premia</th>\n",
       "      <th>AQR CS Premia</th>\n",
       "      <th>FF5 CS Premia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKTBeta</th>\n",
       "      <td>0.084562</td>\n",
       "      <td>0.085667</td>\n",
       "      <td>0.10217</td>\n",
       "      <td>0.087644</td>\n",
       "      <td>0.095697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMBBeta</th>\n",
       "      <td>0.011206</td>\n",
       "      <td></td>\n",
       "      <td>-0.06256</td>\n",
       "      <td></td>\n",
       "      <td>-0.057674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMLBeta</th>\n",
       "      <td>0.025324</td>\n",
       "      <td></td>\n",
       "      <td>-0.015919</td>\n",
       "      <td>-0.039757</td>\n",
       "      <td>-0.033504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMWBeta</th>\n",
       "      <td>0.046525</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.044399</td>\n",
       "      <td>0.035899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMABeta</th>\n",
       "      <td>0.032492</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.015156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMDBeta</th>\n",
       "      <td>0.060925</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.053375</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time Series Premia CAPM CS Premia FF3 CS Premia AQR CS Premia  \\\n",
       "MKTBeta            0.084562       0.085667       0.10217      0.087644   \n",
       "SMBBeta            0.011206                     -0.06256                 \n",
       "HMLBeta            0.025324                    -0.015919     -0.039757   \n",
       "RMWBeta            0.046525                                   0.044399   \n",
       "CMABeta            0.032492                                              \n",
       "UMDBeta            0.060925                                   0.053375   \n",
       "\n",
       "        FF5 CS Premia  \n",
       "MKTBeta      0.095697  \n",
       "SMBBeta     -0.057674  \n",
       "HMLBeta     -0.033504  \n",
       "RMWBeta      0.035899  \n",
       "CMABeta     -0.015156  \n",
       "UMDBeta                "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([time_series_premia, CAPM_CS_premia, FF3_CS_Premia, AQR_CS_premia, FF5_CS_Premia], axis = 1).fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71655c46",
   "metadata": {},
   "source": [
    "**Answer**: cross-sectional estimated premia and time series premia of the factors don't differ substantially in most factor models. However, there are a few exceptions: SMB in FF3 and FF5; HML in FF3, AQR, and FF5; CMA in FF5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7393fc",
   "metadata": {},
   "source": [
    "As an additional clarification, for cross-sectional regression one can check R2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0014ec5",
   "metadata": {},
   "source": [
    "### (b) Report the MAE of the cross-sectional regression residuals for each of the four models, (the Ï…i.) How do they compare to the MAE of the time-series alphas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54bf0406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Series MAE</th>\n",
       "      <th>Cross Section MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AQR</th>\n",
       "      <td>0.020608</td>\n",
       "      <td>0.016395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>0.020608</td>\n",
       "      <td>0.020655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF-3</th>\n",
       "      <td>0.022568</td>\n",
       "      <td>0.014554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF-5</th>\n",
       "      <td>0.031272</td>\n",
       "      <td>0.012982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time Series MAE  Cross Section MAE\n",
       "AQR          0.020608           0.016395\n",
       "MKT          0.020608           0.020655\n",
       "FF-3         0.022568           0.014554\n",
       "FF-5         0.031272           0.012982"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE_TS = pd.Series([AQR_MAE, mkt_MAE, ff3_MAE, ff5_MAE], index = [\"AQR\", \"MKT\", \"FF-3\", \"FF-5\"])\n",
    "MAE_CS = pd.Series([AQR_CS_MAE, CAPM_CS_MAE, FF3_CS_MAE, FF5_CS_MAE], index = MAE_TS.index)\n",
    "MAE = pd.concat([MAE_TS,MAE_CS], axis = 1)\n",
    "MAE.columns = ['Time Series MAE', 'Cross Section MAE']\n",
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97088e1",
   "metadata": {},
   "source": [
    "**Answer**: The MAE of cross-sectional regression is in general lower than the MAE of alphas in time-series regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51e6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
