{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea51ebf",
   "metadata": {},
   "source": [
    "# Homework 8\n",
    "\n",
    "## FINM 36700 - 2023\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "**Professor**\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbaad58",
   "metadata": {},
   "source": [
    "**Students**\n",
    "\n",
    "Anya Zakharov azakharov@uchicago.edu\n",
    "\n",
    "Gleb Skvortsov goskvortsov@uchicago.edu\n",
    "\n",
    "Kai Wen Tay kaiwent@uchicago.edu\n",
    "\n",
    "Ka Hang Toong khtoong@uchicago.edu\n",
    "\n",
    "\n",
    "Tikhonov Sergei tikhonov@uchicago.edu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfdc6a0",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13579956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from arch import arch_model\n",
    "from arch.univariate import GARCH\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ff551",
   "metadata": {},
   "source": [
    "## Helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0723c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_summary(return_data):\n",
    "\n",
    "    summary_stats = return_data.mean().to_frame('Mean').apply(lambda x: x*12)\n",
    "    summary_stats['Volatility'] = return_data.std().apply(lambda x: x*np.sqrt(12))\n",
    "    summary_stats['Sharpe Ratio'] = summary_stats['Mean']/summary_stats['Volatility']\n",
    "    \n",
    "    summary_stats['Skewness'] = return_data.skew()\n",
    "    summary_stats['Excess Kurtosis'] = return_data.kurtosis()\n",
    "    summary_stats['VaR (0.05)'] = return_data.quantile(.05, axis = 0)\n",
    "    summary_stats['CVaR (0.05)'] = return_data[return_data <= return_data.quantile(.05, axis = 0)].mean()\n",
    "\n",
    "    \n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a42b18",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8840c38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fund Capital ($billions)</th>\n",
       "      <th>GrossLTCM</th>\n",
       "      <th>NetLTCM</th>\n",
       "      <th>Index of Net Performance</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1994-03-31</th>\n",
       "      <td>1.097033</td>\n",
       "      <td>-0.013967</td>\n",
       "      <td>-0.015967</td>\n",
       "      <td>0.987033</td>\n",
       "      <td>-0.044868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-04-30</th>\n",
       "      <td>1.096692</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.996692</td>\n",
       "      <td>0.007904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-05-31</th>\n",
       "      <td>1.196408</td>\n",
       "      <td>0.064408</td>\n",
       "      <td>0.049408</td>\n",
       "      <td>1.046408</td>\n",
       "      <td>0.012348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-06-30</th>\n",
       "      <td>1.196450</td>\n",
       "      <td>-0.042550</td>\n",
       "      <td>-0.032550</td>\n",
       "      <td>1.016450</td>\n",
       "      <td>-0.026429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-07-31</th>\n",
       "      <td>1.396342</td>\n",
       "      <td>0.112342</td>\n",
       "      <td>0.080342</td>\n",
       "      <td>1.096342</td>\n",
       "      <td>0.028668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fund Capital ($billions)  GrossLTCM   NetLTCM  \\\n",
       "Date                                                        \n",
       "1994-03-31                  1.097033  -0.013967 -0.015967   \n",
       "1994-04-30                  1.096692   0.010692  0.004692   \n",
       "1994-05-31                  1.196408   0.064408  0.049408   \n",
       "1994-06-30                  1.196450  -0.042550 -0.032550   \n",
       "1994-07-31                  1.396342   0.112342  0.080342   \n",
       "\n",
       "            Index of Net Performance       SPY  \n",
       "Date                                            \n",
       "1994-03-31                  0.987033 -0.044868  \n",
       "1994-04-30                  0.996692  0.007904  \n",
       "1994-05-31                  1.046408  0.012348  \n",
       "1994-06-30                  1.016450 -0.026429  \n",
       "1994-07-31                  1.096342  0.028668  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portdf = pd.read_excel('ltcm_exhibits_data.xlsx', sheet_name=1, skiprows=(0,1), usecols='A:E').dropna().rename(columns={'Unnamed: 0':'Date','Gross Monthly Performancea':'GrossLTCM','Net Monthly Performanceb':'NetLTCM'}).set_index('Date')\n",
    "portdf.index = portdf.index.to_period('M').to_timestamp('M')\n",
    "\n",
    "rets = pd.read_excel('gmo_analysis_data.xlsx', sheet_name=2, usecols = \"A:B\").rename(columns={'Unnamed: 0': 'Date'}).set_index('Date').loc['1994-03':'1998-07']\n",
    "portdf['SPY'] = rets['SPY']\n",
    "\n",
    "rf = pd.read_excel('gmo_analysis_data.xlsx', sheet_name=3).rename(columns={'Unnamed: 0': 'Date'}).set_index('Date').loc['1994-03':'1998-07']\n",
    "retsx = portdf.subtract(rf['US3M'],axis=0)\n",
    "\n",
    "retsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44aba41",
   "metadata": {},
   "source": [
    "## 2 LTCM Risk Decomposition\n",
    "\n",
    "• On Canvas, find the data file, “ltcm exhibits data.xlsx”. Get the gross and net (total) returns\n",
    "of LTCM from “Exhibit 2”.\n",
    "\n",
    "• Get the returns on SPY as well as the risk-free rate from the file, “gmo analysis data”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f24732",
   "metadata": {},
   "source": [
    "### 1 Summary stats.\n",
    "\n",
    "(a) For both the gross and net series of LTCM excess returns, report the mean, volatility, and Sharpe ratios. (Annualize them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391253e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GrossLTCM</th>\n",
       "      <td>0.293887</td>\n",
       "      <td>0.136354</td>\n",
       "      <td>2.155321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetLTCM</th>\n",
       "      <td>0.207170</td>\n",
       "      <td>0.111904</td>\n",
       "      <td>1.851315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>0.225633</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>2.004777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean  Volatility  Sharpe Ratio\n",
       "GrossLTCM  0.293887    0.136354      2.155321\n",
       "NetLTCM    0.207170    0.111904      1.851315\n",
       "SPY        0.225633    0.112547      2.004777"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vol_performance = []\n",
    "series = ['GrossLTCM', 'NetLTCM', 'SPY']\n",
    "\n",
    "for elem in series:\n",
    "    mean_vol_performance.append(performance_summary(portdf[[elem]])[['Mean', 'Volatility', 'Sharpe Ratio']])\n",
    "pd.concat(mean_vol_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e3f5de",
   "metadata": {},
   "source": [
    "(b) Report the skewness, kurtosis, and (historic) VaR(.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50ba0168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "      <th>VaR (0.05)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GrossLTCM</th>\n",
       "      <td>-0.296428</td>\n",
       "      <td>1.569354</td>\n",
       "      <td>-0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetLTCM</th>\n",
       "      <td>-0.817870</td>\n",
       "      <td>2.905537</td>\n",
       "      <td>-0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>-0.436267</td>\n",
       "      <td>-0.370029</td>\n",
       "      <td>-0.042796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Skewness  Excess Kurtosis  VaR (0.05)\n",
       "GrossLTCM -0.296428         1.569354   -0.026400\n",
       "NetLTCM   -0.817870         2.905537   -0.022400\n",
       "SPY       -0.436267        -0.370029   -0.042796"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tail_performance = []\n",
    "series = ['GrossLTCM', 'NetLTCM', 'SPY']\n",
    "\n",
    "for elem in series:\n",
    "    tail_performance.append(performance_summary(portdf[[elem]])[['Skewness', 'Excess Kurtosis', 'VaR (0.05)']])\n",
    "pd.concat(tail_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4920c",
   "metadata": {},
   "source": [
    "(c) Comment on how these stats compare to SPY and other assets we have seen. How much do they differ between gross and net?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f8dc2a",
   "metadata": {},
   "source": [
    "**Mean-vol returns**:\n",
    "\n",
    "GrossLTCM has substantially larger mean excess returns and slightly higher volatility, hence higher Sharpe Ratio. However, NetLTCM has lower mean excess returns compared to SPY, and relatively same volatility. \n",
    "\n",
    "**Tail risk metrics**:\n",
    "\n",
    "NetLTCM shows much more tail risk that SPY does. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312da43",
   "metadata": {},
   "source": [
    "### 2 \n",
    "\n",
    "Using the series of net LTCM excess returns, denoted $\\tilde{r}^{\\text{LTCM}}$, estimate the following regression:\n",
    "\n",
    "$$\n",
    "\\tilde{r}^{\\text{LTCM}} = \\alpha + \\beta^m \\tilde{r}^{m} + \\epsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3bf8f",
   "metadata": {},
   "source": [
    "(a) Report $\\alpha$ and $\\beta^m$. Report the $R^2$ stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "459bb6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Market beta</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>0.175588</td>\n",
       "      <td>0.139969</td>\n",
       "      <td>0.019817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Alpha  Market beta        R2\n",
       "Stats  0.175588     0.139969  0.019817"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.tools.add_constant(portdf['SPY'])\n",
    "y = portdf['NetLTCM']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "alpha = model.params[0]\n",
    "beta = model.params[1]\n",
    "RSquared = model.rsquared\n",
    "\n",
    "pd.DataFrame({'Alpha': alpha * 12, 'Market beta': beta, 'R2': RSquared}, index = ['Stats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278b1b6",
   "metadata": {},
   "source": [
    "(b) From this regression, does LTCM appear to be a “closet indexer”?\n",
    "\n",
    "**Answer**: We obtained very small $R^2$ for pairwise regression. As a result, excess net returns of LTCM have small correlation with market returns, so we cannot conclude that LTCM appear to be a \"closet indexer\". This result is expected, because the strategy of this fund was believed to be market neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b467d77",
   "metadata": {},
   "source": [
    "(c) From the regression, does LTCM appear to deliver excess returns beyond the risk premium\n",
    "we expect from market exposure?\n",
    "\n",
    "**Answer**: LTCM indeed provides substantial excess returns beyond the market. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f049aff9",
   "metadata": {},
   "source": [
    "3 Let’s check for non-linear market exposure. Run the following regression on LTCM’s net excess returns:\n",
    "\n",
    "$$\n",
    "\\tilde{r}^{\\text{LTCM}} = \\alpha + \\beta_1 \\tilde{r}^{m} + \\beta_2 (\\tilde{r}^{m})^2 + \\epsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33eba8",
   "metadata": {},
   "source": [
    "(a) Report $\\beta_1$, $\\beta_2$ and the $R^2$ stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7a79705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta 1</th>\n",
       "      <th>Beta 2</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>0.198894</td>\n",
       "      <td>0.189561</td>\n",
       "      <td>-2.069263</td>\n",
       "      <td>0.025977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Alpha    Beta 1    Beta 2        R2\n",
       "Stats  0.198894  0.189561 -2.069263  0.025977"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.tools.add_constant(pd.concat([portdf['SPY'], portdf['SPY'] ** 2], axis = 1))\n",
    "y = portdf['NetLTCM']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "alpha = model.params[0]\n",
    "beta_1 = model.params[1]\n",
    "beta_2 = model.params[2]\n",
    "RSquared = model.rsquared\n",
    "\n",
    "pd.DataFrame({'Alpha': alpha * 12, 'Beta 1': beta_1, 'Beta 2': beta_2, 'R2': RSquared}, index = ['Stats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b389205",
   "metadata": {},
   "source": [
    "(b) Does the quadratic market factor do much to increase the overall LTCM variation explained\n",
    "by the market?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1c0fb",
   "metadata": {},
   "source": [
    "**Answer**: Even though significant negative Beta 2 indicates non-linear market exposure, we still observe small $R^2$ and hence quadratic market factor does not improve regression performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de09b30f",
   "metadata": {},
   "source": [
    "(c) From the regression evidence, does LTCM’s market exposure behave as if it is long market\n",
    "options or short market options?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6df82d",
   "metadata": {},
   "source": [
    "**Answer**: As was observed above, we obtained negative quadratic beta of market factor. It means that for large enough returns of market, the higher excess market returns are the lower excess LTCM returns. As a result, we can conclude that LTCM market exposure behave as if it is short market options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853f300",
   "metadata": {},
   "source": [
    "(d) Should we describe LTCM as being positively or negatively exposed to market volatility?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af010e",
   "metadata": {},
   "source": [
    "**Answer**: We observed that LTCM market exposure behave as if it is short market options, we can conclude the fund negatively exposed to market volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7fa33",
   "metadata": {},
   "source": [
    "### 4\n",
    "\n",
    "Let’s try to pinpoint the nature of LTCM’s nonlinear exposure. Does it come more from exposure\n",
    "to up-markets or down-markets? Run the following regression on LTCM’s net excess returns:\n",
    "\n",
    "$$\n",
    "\\tilde{r}^{\\text{LTCM}} = \\alpha + \\beta \\tilde{r}^m_t + \\beta_u \\max(\\tilde{r}^m_t - k_1, 0) + \\beta_d \\max(k_2 - \\tilde{r}^m_t, 0) + \\epsilon_t\n",
    "$$\n",
    "\n",
    "where k1 = .03 and k2 = −.03. (This is roughly one standard deviation of $\\tilde{r}^m$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "342628a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Beta u</th>\n",
       "      <th>Beta d</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stats</th>\n",
       "      <td>0.138157</td>\n",
       "      <td>0.493472</td>\n",
       "      <td>-0.760903</td>\n",
       "      <td>1.572423</td>\n",
       "      <td>0.054671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Alpha      Beta    Beta u    Beta d        R2\n",
       "Stats  0.138157  0.493472 -0.760903  1.572423  0.054671"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = .03\n",
    "k2 = -.03\n",
    "\n",
    "up_market = np.maximum(portdf['SPY'] - k1, 0)\n",
    "down_market = np.maximum(k2 - portdf['SPY'], 0)\n",
    "\n",
    "X = sm.tools.add_constant(pd.concat([portdf['SPY'], up_market, down_market], axis = 1))\n",
    "y = portdf['NetLTCM']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "alpha = model.params[0]\n",
    "beta = model.params[1]\n",
    "beta_u = model.params[2]\n",
    "beta_d = model.params[3]\n",
    "RSquared = model.rsquared\n",
    "\n",
    "pd.DataFrame({'Alpha': alpha * 12, 'Beta': beta, 'Beta u': beta_u, \n",
    "              'Beta d': beta_d, 'R2': RSquared}, index = ['Stats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72e54f",
   "metadata": {},
   "source": [
    "Is LTCM long or short the call-like factor? And the put-like factor?\n",
    "\n",
    "**Answer**: According to Beta up and Beta down, we can conclude that LTCM short call-like factor and long put-like factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8fdae",
   "metadata": {},
   "source": [
    "(c) Which factor moves LTCM more, the call-like factor, or the put-like factor?\n",
    "\n",
    "**Answer**: the put-like factor moves excess returns of LTCM more than call-like factor does, since absolute value of Beta u is higher than that of Beta d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f8d18",
   "metadata": {},
   "source": [
    "(d) In the previous problem, you commented on whether LTCM is positively or negatively\n",
    "exposed to market volatility. Using this current regression, does this volatility exposure\n",
    "come more from being long the market’s upside? Short the market’s downside? Something\n",
    "else?\n",
    "\n",
    "**Answer**: negative exposure is driven by shorting market upside, because of large positive Beta d (put-like factor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b889645",
   "metadata": {},
   "source": [
    "## 3 The FX Carry Trade\n",
    "\n",
    "Find an Excel data file, “fx carry data.xlsx”. The file has two sets of data:\n",
    "\n",
    "• Risk-free rates across 5 currencies, as measured by annualized 3-month LIBOR rates.\n",
    "\n",
    "• Spot FX rates, as direct quotes to the USD. (Note that all currencies are quoted as USD per\n",
    "the foreign currency.)\n",
    "\n",
    "For use in the homework, note the following:\n",
    "\n",
    "• For risk-free rate data, $r^{f, i}_{t, t+1}$, the rate is known and reported in the data at time $t$. Namely,\n",
    "any given date $t$ in the data file is reporting both $S^i_t$ and $r^{f, i}_{t, t+1}$.\n",
    "\n",
    "• The theory says to use log risk-free rates. You have the risk-free rate in levels: use the following\n",
    "equation to convert them:\n",
    "\n",
    "$$\n",
    "r^{f, i}_{t, t+1} = ln(1 + r^{f, i}_{t, t+1})\n",
    "$$\n",
    "\n",
    "• The theory says to use log spot FX prices. You have the FX prices in levels, so directly take\n",
    "their logarithims:\n",
    "\n",
    "$$\n",
    "s^i_t = ln(S^i_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fd6a85",
   "metadata": {},
   "source": [
    "### 1 The Static Carry Trade\n",
    "\n",
    "Define the log return of holding the foreign currency using log values of the risk-free rate and\n",
    "log values of the FX rates:\n",
    "\n",
    "$$\n",
    "r^i_{t+1} = s^i_{t+1} - s^i_t + r^{f, i}_{t, t+1}\n",
    "$$\n",
    "\n",
    "Then the excess log return relative to USD, is expressed as\n",
    "\n",
    "$$\n",
    "\\tilde{r}^i_{t+1} = s^i_{t+1} - s^i_{t} + r^{f, i}_{t, t+1} - r^{f, $}_{t, t+1}\n",
    "$$\n",
    "\n",
    "For each foreign currency, i, calculate the excess log return series, ˜rt+1. Report the following\n",
    "stats, (based on the excess log returns.) Annualize them.\n",
    "\n",
    "(a) mean\n",
    "\n",
    "(b) volatility\n",
    "\n",
    "(c) Sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bd1504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fxspot = pd.read_excel('fx_carry_data.xlsx',sheet_name=2,index_col='DATE')\n",
    "rf = pd.read_excel('fx_carry_data.xlsx',sheet_name=1,index_col='DATE')\n",
    "\n",
    "logrf = np.log(1 + rf).shift()\n",
    "logfxspot = np.log(fxspot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cf85dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USUK</th>\n",
       "      <td>-0.003502</td>\n",
       "      <td>0.086303</td>\n",
       "      <td>-0.040574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USEU</th>\n",
       "      <td>-0.004351</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>-0.045944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USSZ</th>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.098757</td>\n",
       "      <td>0.043662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USJP</th>\n",
       "      <td>-0.017415</td>\n",
       "      <td>0.091492</td>\n",
       "      <td>-0.190342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Volatility  Sharpe Ratio\n",
       "USUK -0.003502    0.086303     -0.040574\n",
       "USEU -0.004351    0.094714     -0.045944\n",
       "USSZ  0.004312    0.098757      0.043662\n",
       "USJP -0.017415    0.091492     -0.190342"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vol_performance = []\n",
    "series = ['USUK', 'USEU', 'USSZ', 'USJP']\n",
    "\n",
    "excess_log_fx = pd.DataFrame(index=logfxspot.index)\n",
    "excess_log_fx['USUK'] = logfxspot.diff()['USUK'] + logrf['GBP1M'] - logrf['USD1M']\n",
    "excess_log_fx['USEU'] = logfxspot.diff()['USEU'] + logrf['EUR1M'] - logrf['USD1M']\n",
    "excess_log_fx['USSZ'] = logfxspot.diff()['USSZ'] + logrf['CHF1M'] - logrf['USD1M']\n",
    "excess_log_fx['USJP'] = logfxspot.diff()['USJP'] + logrf['JPY1M'] - logrf['USD1M']\n",
    "excess_log_fx = excess_log_fx.dropna()\n",
    "\n",
    "for elem in series:\n",
    "    mean_vol_performance.append(performance_summary(excess_log_fx[[elem]])[['Mean', 'Volatility', 'Sharpe Ratio']])\n",
    "pd.concat(mean_vol_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036f84b",
   "metadata": {},
   "source": [
    "What differences do you see across currencies?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "The only currency pair that indicates positive Sharpe Ratio is the pair of US dollar and CHF. Volatilities are comparable among all the currencies. The pair of US dollar and Japanese Yen has the lowest mean returns (4 times less than any other currency)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69745211",
   "metadata": {},
   "source": [
    "### 2 Implications for UIP:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abbbba",
   "metadata": {},
   "source": [
    "(a) Do any of these stats contradict the (log version) of Uncovered Interest Parity (UIP)?\n",
    "\n",
    "**Answer**: We can see that all USUK, USEU, USSZ very small mean excess returns, the fact which corresponds to Uncovered Interest Parity (UIP). However, USJP has relatively high absolute mean excess returns, which can indicate contradiction to UIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a2bd4",
   "metadata": {},
   "source": [
    "(b) A long position in which foreign currency offered the best Sharpe ratio over the sample?\n",
    "\n",
    "**Answer**: According to computations provided above, the long USD and short JPY position can provide 1.74% returns and result 0.19 Sharpe ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df756801",
   "metadata": {},
   "source": [
    "(c) Are there any foreign currencies for which a long position earned a negative excess return\n",
    "(in USD) over the sample?\n",
    "\n",
    "**Answer**: Since USUK, USEU, and USJP have all negative mean returns, it indicates that a long position earned negative excess returns. However, USSZ has a positive mean return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c9ce3",
   "metadata": {},
   "source": [
    "### 3 Predicting FX\n",
    "\n",
    "For each foreign currency, test whether interest-rate differentials can predict growth in the\n",
    "foreign-exchange rate. Do this by estimating the following forecasting regression:\n",
    "\n",
    "$$\n",
    "s^i_{t+1} - s^i_t = \\alpha^i + \\beta^i (r^{f, $}_{t, t+1} - r^{f, i}_{t, t+1}) + \\epsilon^i_{t+1}\n",
    "$$\n",
    "\n",
    "where $r^{f, i}$ denotes the risk-free rate of currency $i$, and $s^i$ denotes the FX rate for currency $i$. Again, note that both $r^{f, $}_{t, t+1}$ and $s_t$ are determined at time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910b329",
   "metadata": {},
   "source": [
    "(a) Make a table with columns corresponding to a different currency regression. Report the\n",
    "regression estimates $\\alpha^i$ and $\\beta^i$ in the first two rows. Report the $R^2$ stat in the third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "281cd076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USUK</th>\n",
       "      <th>USEU</th>\n",
       "      <th>USSZ</th>\n",
       "      <th>USJP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>-0.005868</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.043574</td>\n",
       "      <td>-0.005996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.485836</td>\n",
       "      <td>-1.256358</td>\n",
       "      <td>-1.646596</td>\n",
       "      <td>0.371473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           USUK      USEU      USSZ      USJP\n",
       "alpha -0.005868  0.007033  0.043574 -0.005996\n",
       "beta   0.485836 -1.256358 -1.646596  0.371473\n",
       "R2     0.000382  0.002610  0.003948  0.000501"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = {'USUK': logrf['USD1M'] - logrf['GBP1M'], 'USEU': logrf['USD1M'] - logrf['EUR1M'],\n",
    " 'USSZ': logrf['USD1M'] - logrf['CHF1M'], 'USJP': logrf['USD1M'] - logrf['JPY1M']}\n",
    "X = pd.DataFrame(diff).dropna()\n",
    "y = logfxspot.diff().dropna()\n",
    "\n",
    "results = []\n",
    "\n",
    "for pair in X.columns:\n",
    "    X_pair = sm.tools.add_constant(X[pair])\n",
    "    y_pair = y[pair]\n",
    "\n",
    "    model = sm.OLS(y_pair, X_pair).fit()\n",
    "\n",
    "    alpha = model.params[0]\n",
    "    beta = model.params[1]\n",
    "    RSquared = model.rsquared\n",
    "    results.append(pd.DataFrame({'alpha': alpha * 12, 'beta': beta, 'R2': RSquared}, index=[pair]))\n",
    "    \n",
    "res = pd.concat(results).T\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e4a21",
   "metadata": {},
   "source": [
    "(b) Suppose the foreign risk-free rate increases relative to the US rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2f045",
   "metadata": {},
   "source": [
    "1 For which foreign currencies would we predict a relative strengthening of the USD in\n",
    "the following period?\n",
    "\n",
    "**Answer**: To answer this question, we can look at the signs of betas. \n",
    "\n",
    "$$\n",
    "s^i_{t+1} - s^i_t = \\alpha^i + \\beta^i (r^{f, $}_{t, t+1} - r^{f, i}_{t, t+1}) + \\epsilon^i_{t+1}\n",
    "$$\n",
    "\n",
    "According to the task:\n",
    "\n",
    "$$\n",
    "r^{f, $}_{t, t+1} - r^{f, i}_{t, t+1} < 0 \n",
    "$$\n",
    "\n",
    "Then to expect a relative strengthening of the USD in the following period we need positive beta, which is the case for UK and JP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75772c2",
   "metadata": {},
   "source": [
    "2 For which currencies would we predict relative weakening of the USD in the following\n",
    "\n",
    "**Answer**: For now, we have:\n",
    "\n",
    "According to the task:\n",
    "\n",
    "$$\n",
    "r^{f, $}_{t, t+1} - r^{f, i}_{t, t+1} > 0 \n",
    "$$\n",
    "\n",
    "Then to expect a relative strengthening of the USD in the following period we need negative beta, which is the case for EU and SZ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001b503",
   "metadata": {},
   "source": [
    "3 This FX predictability is strongest in the case of which foreign currency?\n",
    "\n",
    "**Answer**: According to $R^2$, we can conclude that predictability is the strongest in the case of SZ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388f9cd0",
   "metadata": {},
   "source": [
    "### 4 The Dynamic Carry Trade\n",
    "Use this to write $\\mathbb{E}_t(\\tilde{r}^i_{t+1})$ as a function of the interest-rate differential as well as $\\alpha$ and $\\beta$ from this FX regression.\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_t(s_{t+1} - s_t) = \\alpha + \\beta(r^{f, $}_{t, t+1} - r^{f, i}_{t, t+1})\n",
    "$$\n",
    "\n",
    "Then use the definition of excess (log) returns on FX:\n",
    "\n",
    "$$\n",
    "\\tilde{r}^{i}_{t+1} = s_{t+1} - s_t - (r^{f, $}_{t, t+1} - r^{f, i}_{t, t+1})\n",
    "$$\n",
    "\n",
    "Rearranging, this implies the following forecast for excess log returns:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_t(\\tilde{r}^{i}_{t+1}) = \\alpha + (\\beta - 1)(r^{f, $}_{t, t+1} - r^{f, i}_{t, t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a999328",
   "metadata": {},
   "source": [
    "(a) Use your regression estimates from Problem 3 along with the formula above to calculate\n",
    "the fraction of months for which the estimated FX risk premium positive. That is, for each\n",
    "i, calculate how often in the time-series we have:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_t(\\tilde{r}^i_{t+1}) > 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c0bc39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected USUK > 0 : 24.0%\n",
      "Expected USEU > 0 : 50.0%\n",
      "Expected USSZ > 0 : 63.0%\n",
      "Expected USJP > 0 : 0.0%\n"
     ]
    }
   ],
   "source": [
    "USUK_pred = res['USUK']['alpha'] / 12 + (res['USUK']['beta'] - 1) * X['USUK']\n",
    "USEU_pred = res['USEU']['alpha'] / 12 + (res['USEU']['beta'] - 1) * X['USEU']\n",
    "USSZ_pred = res['USSZ']['alpha'] / 12 + (res['USSZ']['beta'] - 1) * X['USSZ']\n",
    "USJP_pred = res['USJP']['alpha'] / 12 + (res['USJP']['beta'] - 1) * X['USJP']\n",
    "\n",
    "print(f'Expected USUK > 0 : {round(sum(USUK_pred > 0) / len(USUK_pred), 2) * 100}%')\n",
    "print(f'Expected USEU > 0 : {round(sum(USEU_pred > 0) / len(USEU_pred), 2) * 100}%')\n",
    "print(f'Expected USSZ > 0 : {round(sum(USSZ_pred > 0) / len(USSZ_pred), 2) * 100}%')\n",
    "print(f'Expected USJP > 0 : {round(sum(USJP_pred > 0) / len(USJP_pred), 2) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c5821",
   "metadata": {},
   "source": [
    "(b) Which currencies most consistently have a positive FX risk premium? And for which\n",
    "currencies does the FX risk premium most often go negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed1206",
   "metadata": {},
   "source": [
    "**Answer**: As can be seen from the formulas above, EU and SZ have most consistently positive FX risk premiums, while UK and JP risk premiums are mostly negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41da88b",
   "metadata": {},
   "source": [
    "(c) Explain how we could use these conditional risk premia to improve the static carry trade\n",
    "returns calculated in Problem 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4997055",
   "metadata": {},
   "source": [
    "**Answer**: the fund can improve the static carry trade returns by taking advantage of conditional risk premia: borrowing at the JPY's risk-free rate and then investing in the risk-free rate of the US Dollar. Considering our prediction of the USD gaining strength against the JPY, this strategy could yield a significant risk premium from the carry trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb190ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
